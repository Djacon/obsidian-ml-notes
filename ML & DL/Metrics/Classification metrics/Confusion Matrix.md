**Confusion Matrix** is a [[metric]] table that is used to evaluate the performance of a [[Machine Learning]] algorithm. It provides a summary of the number of correct and incorrect predictions made by the algorithm, compared to the actual results

![[Confusion_matrix_image.jpg]]

#### Pros and Cons:

* Pros:
	* Provides detailed information
	* Helps identify performance issues
	* Useful for model comparison
	* Can be used for multi-class problems
* Cons:
	* Bad for imbalanced data
	* Can be misleading (may have a high accuracy but still perform poorly on a particular data)