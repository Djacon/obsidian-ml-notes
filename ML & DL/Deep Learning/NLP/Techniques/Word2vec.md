**Word2Vec** is a classical method that creates [[Word Embeddings]] in the field of [[Natural Language Processing|NLP]]. It was developed by Tomas Mikolov and his team at Google in 2013. Word2vec takes in words from a large corpus of texts as input and learns to give out their vector representation


![[Word2vec_image.png]]